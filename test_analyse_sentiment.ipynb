{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imporation des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### modules pour le chargement des données depuis le XML ######\n",
    "import glob\n",
    "from lxml import etree\n",
    "from preTraitements.xml import get_X_Y_from_root\n",
    "from preTraitements.xml import get_tree_root_from_file\n",
    "\n",
    "###### modules pour la classification ######\n",
    "\n",
    "# modèles\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# vectorisation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# création de nos transformers\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.feature_extraction import DictVectorizer # créer nos propres transformer\n",
    "\n",
    "# recherche des meilleurs hyperparamètres\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# résultats\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# sauvegarde des modèles\n",
    "from joblib import dump, load\n",
    "\n",
    "# spécifique pour l'analyse de sentiments\n",
    "#%pip install transformers[sentencepiece]\n",
    "#%pip install torch\n",
    "from transformers import pipeline\n",
    "\n",
    "###### modules pour la visualisation ######\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "###### miscellaneous ######\n",
    "from typing import List # typage des fonctions\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import namedtuple\n",
    "import glob as glb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des fichiers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus politiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_train, root_train = get_tree_root_from_file(\"./corpus/train_deft09_parlement_appr.xml/deft09_parlement_appr_fr.xml\")\n",
    "X_train, y_train = get_X_Y_from_root(root_train)\n",
    "\n",
    "tree_test, root_test = get_tree_root_from_file(\"./corpus/deft09_parlement_test.xml/deft09_parlement_test_fr.xml\")\n",
    "X_test, _ = get_X_Y_from_root(root_test) # y_test est vide : pas accès aux résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on récupère le y_test qui est dans un autre fichier\n",
    "\n",
    "y_test = []\n",
    "folder =  \"./corpus/deft09_parlement_ref/\"\n",
    "files_ref = glb.glob(folder+\"deft09_parlement_ref_fr.txt\")[0]\n",
    "\n",
    "with open(files_ref,'r') as file:\n",
    "    line = file.readline()\n",
    "    while line:\n",
    "        line = line.split(\"\\t\")\n",
    "        y_test.append(line[1])\n",
    "        line = file.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# échantillon pour tester plus rapidement\n",
    "\n",
    "X_train_sample = X_train[:100]\n",
    "y_train_sample = y_train[:100]\n",
    "X_test_sample = X_test[:100]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse de sentiments\n",
    "\n",
    "Pour l'instant, j'ai testé avec : \n",
    "\n",
    "- SVM : meilleur sans\n",
    "- RandomForestClassifier : meilleur sans\n",
    "- régression logistique : exactement la même chose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargez le modèle de transformer pré-entraîné\n",
    "sentiment_model = pipeline(\"sentiment-analysis\", \n",
    "                           model=\"nlptown/bert-base-multilingual-uncased-sentiment\") # uncased parce que ne prend pas en compte la casse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_pred(posts):\n",
    "    global sentiment_model\n",
    "    return sentiment_model(posts, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajoutez les prédictions de sentiments à votre pipeline de classification de discours politiques\n",
    "\n",
    "pipeline_avec_sent = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('counts', CountVectorizer()),\n",
    "            ('tf_idf', TfidfTransformer())\n",
    "        ])),\n",
    "        ('sentiments', Pipeline([\n",
    "          ('stats', FunctionTransformer(sentiment_pred)),\n",
    "          ('vect', DictVectorizer())\n",
    "        ]))\n",
    "    ])),\n",
    "    ('reglog', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Entraînez le modèle de classification de discours politiques sur les données d'entraînement\n",
    "pipeline_avec_sent.fit(X_train_sample, y_train_sample)\n",
    "\n",
    "cv_scores_avec_sentiment = cross_val_score(pipeline_avec_sent, X_train_sample, y_train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.mean(cv_scores_avec_sentiment))\n",
    "print(cv_scores_avec_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_sans_sent = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('counts', CountVectorizer()),\n",
    "            ('tf_idf', TfidfTransformer())\n",
    "        ])),\n",
    "    ])),\n",
    "    ('reglog', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipeline_sans_sent.fit(X_train_sample, y_train_sample)\n",
    "cv_scores_sans_sent = cross_val_score(pipeline_sans_sent, X_train_sample, y_train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4 , 0.35, 0.25, 0.3 , 0.2 ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.mean(cv_scores_sans_sent))\n",
    "print(cv_scores_sans_sent)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification en thème"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"BaptisteDoyen/camembert-base-xnli\")\n",
    "\n",
    "candidate_labels = [\"sport\", \n",
    "                    \"immigration\", \n",
    "                    \"économie\", \n",
    "                    \"sécurité\",\n",
    "                    \"justice\",\n",
    "                    \"science\", \n",
    "                    \"féminisme\", \n",
    "                    \"culture\", \n",
    "                    \"écologie\", \n",
    "                    \"climat\",\n",
    "                    \"fiscalité\",\n",
    "                    \"animal\",\n",
    "                    \"social\",\n",
    "                    \"agriculture\",\n",
    "                    \"santé\",\n",
    "                    \"travail\",\n",
    "                    \"racisme\"]\n",
    "#hypothesis_template = \"Ce texte parle de {}.\" # on peut peut-être utiliser ça pour renvoyer un dico\n",
    "\n",
    "def theme_predictor(texts):\n",
    "  \"\"\"\n",
    "  Prédire les thèmes dominants des textes donnés en utilisant un modèle de type \"zero-shot\" : BaptisteDoyen/camembert-base-xnli\n",
    "  \n",
    "  Parameters:\n",
    "  texts (list): une liste de chaînes de caractères contenant les textes à classifier.\n",
    "  \n",
    "  Returns:\n",
    "  list: une liste de dictionnaires, où chaque dictionnaire contient une entrée (thème, score) pour chaque thème prédit avec son score associé.\n",
    "  \"\"\"\n",
    "  global theme_classifier\n",
    "  global candidate_labels\n",
    "  \n",
    "  results = []\n",
    "  for text in texts:\n",
    "    classification = theme_classifier(text, candidate_labels)\n",
    "    labels = classification[\"labels\"]\n",
    "    scores = classification[\"scores\"]\n",
    "    results.append({label:score for label, score in zip(labels, scores)})\n",
    "      \n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] START .....................................................................\n"
     ]
    }
   ],
   "source": [
    "# Ajoutez les prédictions de thèmes à votre pipeline de classification de discours politiques\n",
    "\n",
    "pipeline_avec_theme = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('counts', CountVectorizer()),\n",
    "            ('tf_idf', TfidfTransformer())\n",
    "        ])),\n",
    "        ('sentiments', Pipeline([\n",
    "          ('stats', FunctionTransformer(theme_predictor)),\n",
    "          ('vect', DictVectorizer())\n",
    "        ]))\n",
    "    ])),\n",
    "    ('linearsvc', LinearSVC())\n",
    "])\n",
    "\n",
    "# Entraînez le modèle de classification de discours politiques sur les données d'entraînement\n",
    "#pipeline_avec_theme.fit(X_train_sample, y_train_sample)\n",
    "\n",
    "cv_avec_theme = cross_val_score(pipeline_avec_theme, X_train_sample, y_train_sample, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(cv_avec_theme))\n",
    "print(cv_avec_theme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_sans_theme = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('counts', CountVectorizer()),\n",
    "            ('tf_idf', TfidfTransformer())\n",
    "        ])),\n",
    "    ])),\n",
    "    ('reglog', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Entraînez le modèle de classification de discours politiques sur les données d'entraînement\n",
    "#pipeline_sans_theme.fit(X_train_sample, y_train_sample)\n",
    "\n",
    "cv_sans_theme = cross_val_score(pipeline_sans_theme, X_train_sample, y_train_sample, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(cv_sans_theme))\n",
    "print(cv_sans_theme)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7772623b82ed846feb46f5a96aa7fb44349f73638c006ae7e8cad2b5cbf66b21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
